# -*- coding: utf-8 -*-
"""Predictive Anlysis Predictive analysis Sales Supermarket.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1x9oyEq_6k7y2vDlHi8pca1o_q8bOrK-q

##Rahmat Hidayat
##Submission Dicoding Predictive analysis Sales Supermarket

##Pertama, import library yang dibutuhkan.
## Import Library:

* import numpy as np: Mengimpor library NumPy yang digunakan untuk operasi matematis dan manipulasi array.
import pandas as pd: Mengimpor library Pandas yang digunakan untuk analisis data dan manipulasi struktur data seperti DataFrame.
* import matplotlib.pyplot as plt: Mengimpor modul Pyplot dari Matplotlib untuk membuat visualisasi data dalam bentuk grafik.
* import seaborn as sns: Mengimpor Seaborn, yang merupakan library visualisasi data yang dibangun di atas Matplotlib, untuk membuat grafik yang lebih menarik dan informatif.
Pengaturan Visualisasi:

* %matplotlib inline: Menyediakan perintah magic untuk Jupyter Notebook yang memungkinkan grafik yang dihasilkan oleh Matplotlib ditampilkan langsung di dalam notebook.
* Secara keseluruhan, kode ini mempersiapkan lingkungan untuk analisis data dan visualisasi dengan menggunakan beberapa library penting di Python.
"""

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
# %matplotlib inline
import seaborn as sns

"""# Crawling Data

Mendefinisikan URL:

* url = "https://github.com/Rahmathidayat4299/data-machine-learning/raw/refs/heads/master/supermarket_sales%20-%20Sheet1.csv": Kode ini mendefinisikan sebuah variabel url yang menyimpan alamat URL dari file CSV yang akan diunduh. URL ini mengarah ke file data penjualan supermarket yang dihosting di GitHub.
Mengimpor Data dari URL:

* salesmarket = pd.read_csv(url): Kode ini menggunakan fungsi pd.read_csv() dari library Pandas untuk membaca data dari file CSV yang terletak di URL yang telah ditentukan. Data yang diunduh kemudian disimpan dalam variabel salesmarket, yang merupakan sebuah DataFrame Pandas.
Menyimpan dan Menampilkan Data:

* Setelah eksekusi kode ini, variabel salesmarket akan berisi seluruh data dari file CSV yang dapat digunakan untuk analisis lebih lanjut.
"""

url = "https://github.com/Rahmathidayat4299/data-machine-learning/raw/refs/heads/master/supermarket_sales%20-%20Sheet1.csv"
salesmarket = pd.read_csv(url)
salesmarket

"""# Konversi Tinggi

# Cleaning Process Data
Proses membersihkan data mulai dari pengecekan :

* Cek Nilai Null: Kode checksalesnull = salesmarket.isnull().sum() menghitung jumlah nilai null dalam setiap kolom DataFrame salesmarket, memberikan informasi tentang kualitas data.

* Cek Baris Duplikat: Kode checksalesduplicate = salesmarket.duplicated().sum() menghitung total baris duplikat di DataFrame, membantu mengidentifikasi apakah ada data yang redundan.

* Tampilkan Hasil: Kode print() menampilkan jumlah nilai null per kolom, jumlah baris duplikat, dan statistik deskriptif dari DataFrame menggunakan salesmarket.describe(), memberikan gambaran umum tentang distribusi data.

Data yang bersih akan memudah melatih model dan menghasilkan prediksi yang baik
"""

# Cek jumlah nilai null dalam DataFrame
checksalesnull = salesmarket.isnull().sum()

# Cek jumlah baris duplikat dalam DataFrame
checksalesduplicate = salesmarket.duplicated().sum()

# Tampilkan hasil
print("Jumlah nilai null:\n", checksalesnull)
print("Jumlah baris duplikat:", checksalesduplicate)
print(salesmarket.describe())

"""# Penanganan Outlier
Menentukan Kolom Relevan:

* Kode ini mulai dengan mendefinisikan kolom numerik yang relevan (Unit price, Quantity, Total, Rating) untuk analisis outlier.
Menghitung Kuartil dan IQR:

* Menghitung kuartil pertama (Q1) dan kuartil ketiga (Q3) untuk kolom-kolom tersebut menggunakan fungsi quantile(). IQR (Interquartile Range) dihitung sebagai selisih antara Q3 dan Q1, yang digunakan untuk menentukan batasan dalam mendeteksi outlier.
Menentukan Batas Outlier:

* Batas bawah dan batas atas untuk mendeteksi outlier ditentukan dengan rumus:
lower_bound = Q1 - 1.5 * IQR
upper_bound = Q3 + 1.5 * IQR.
Outlier kemudian ditentukan dengan memeriksa apakah nilai-nilai dalam kolom tersebut berada di luar batas yang telah ditentukan.
Menampilkan Hasil:

* Kode ini menampilkan jumlah outlier yang terdeteksi serta informasi mengenai data tersebut. Jika terdapat nilai yang berada di luar batas yang ditetapkan, data tersebut akan dianggap sebagai outlier dan ditampilkan.
"""

import pandas as pd

# Menentukan kolom yang relevan untuk cek outlier
numerical_columns = ['Unit price', 'Quantity', 'Total', 'Rating']

# Menghitung Q1 (Kuartil Pertama) dan Q3 (Kuartil Ketiga)
Q1 = salesmarket[numerical_columns].quantile(0.25)
Q3 = salesmarket[numerical_columns].quantile(0.75)

# Menghitung IQR (Interquartile Range)
IQR = Q3 - Q1

# Menentukan batas bawah dan batas atas untuk mendeteksi outlier
lower_bound = Q1 - 1.5 * IQR
upper_bound = Q3 + 1.5 * IQR

# Menampilkan outlier pada masing-masing kolom
outliers = salesmarket[
    (salesmarket['Unit price'] < lower_bound['Unit price']) | (salesmarket['Unit price'] > upper_bound['Unit price']) |
    (salesmarket['Quantity'] < lower_bound['Quantity']) | (salesmarket['Quantity'] > upper_bound['Quantity']) |
    (salesmarket['Total'] < lower_bound['Total']) | (salesmarket['Total'] > upper_bound['Total']) |
    (salesmarket['Rating'] < lower_bound['Rating']) | (salesmarket['Rating'] > upper_bound['Rating'])
]

# Menampilkan outlier yang terdeteksi
print("Jumlah outlier pada DataFrame:", len(outliers))
print(outliers)

from scipy import stats
import numpy as np

# Menghitung Z-score untuk kolom numerik
z_scores = np.abs(stats.zscore(salesmarket[numerical_columns]))

# Menyaring outlier berdasarkan Z-score > 3
outliers_zscore = salesmarket[(z_scores > 3).any(axis=1)]

# Menampilkan outlier yang terdeteksi
print("Jumlah outlier pada DataFrame berdasarkan Z-score:", len(outliers_zscore))
print(outliers_zscore)

# Menghapus outlier berdasarkan batas bawah dan atas
salesmarketclean = salesmarket[
    (salesmarket['Unit price'] >= lower_bound['Unit price']) & (salesmarket['Unit price'] <= upper_bound['Unit price']) &
    (salesmarket['Quantity'] >= lower_bound['Quantity']) & (salesmarket['Quantity'] <= upper_bound['Quantity']) &
    (salesmarket['Total'] >= lower_bound['Total']) & (salesmarket['Total'] <= upper_bound['Total']) &
    (salesmarket['Rating'] >= lower_bound['Rating']) & (salesmarket['Rating'] <= upper_bound['Rating'])
]

# Menampilkan jumlah data setelah penghapusan outlier
print("Jumlah data setelah outlier dihapus:", len(salesmarketclean))

# Menampilkan beberapa data setelah outlier dihapus
print(salesmarketclean.head())

salesmarketclean.describe()
salesmarketclean.info()
salesmarketclean.duplicated().sum()

"""# Menjawab Pertanyaan
  ## Bagaimana kita bisa memprediksi total penjualan (Total) dari kombinasi variabel seperti jenis pelanggan, jenis produk, dan lokasi cabang?

* Penjelasan kode
* Kode ini melakukan One-Hot Encoding pada variabel kategorikal dalam DataFrame salesmarketclean. Berikut adalah penjelasan singkatnya:

* One-Hot Encoding: Proses ini digunakan untuk mengubah variabel kategorikal menjadi format numerik, sehingga dapat digunakan dalam model machine learning. Setiap kategori dari variabel kategorikal diwakili oleh kolom baru, yang berisi nilai 0 atau 1 (1 jika data memiliki kategori tersebut, 0 jika tidak).

* pd.get_dummies: Fungsi dari pandas yang digunakan untuk melakukan One-Hot Encoding. Parameter columns menentukan kolom mana yang akan diubah menjadi format numerik.

* drop_first=True: Parameter ini menginstruksikan fungsi untuk menghapus satu kolom dari hasil encoding untuk menghindari dummy variable trap, yaitu masalah multikolinearitas yang terjadi ketika salah satu kolom dapat diprediksi dari kolom lainnya.

* Hasil: Variabel kategorikal yang tercantum (Customer type, Product line, Branch, City, Gender, Payment) akan diubah menjadi beberapa kolom biner, dan DataFrame yang dihasilkan disimpan dalam variabel df_encoded.
"""

# Mengubah variabel kategorikal menjadi numerik menggunakan One-Hot Encoding
df_encoded = pd.get_dummies(salesmarketclean, columns=['Customer type', 'Product line', 'Branch', 'City', 'Gender', 'Payment'], drop_first=True)

"""#Model Development
#Langkah 1: Memisahkan Fitur dan Target
Selanjutnya, kita pisahkan fitur (X) dan target (y), di mana target adalah variabel Total.
* Kode dibawah ini  mempersiapkan data dengan menentukan fitur (X) dan target (y) yang akan digunakan untuk membangun model.

Penjelasan Kode:
* Menentukan Fitur (X):
X adalah DataFrame yang berisi semua kolom dari df_encoded kecuali kolom Total, Invoice ID, Date, dan Time. Ini adalah variabel independen yang akan digunakan untuk pelatihan model.
* Menentukan Target (y):
y adalah Series yang berisi nilai dari kolom Total, yang merupakan variabel dependen yang ingin diprediksi oleh model.
"""

# Menentukan fitur dan target
X = df_encoded.drop(columns=['Total', 'Invoice ID', 'Date', 'Time'])  # Menghapus kolom yang tidak relevan
y = df_encoded['Total']

"""## Langkah 2: Membagi Data untuk Pelatihan dan Pengujian
Kita perlu membagi data menjadi data pelatihan dan data pengujian untuk mengevaluasi kinerja model.
"""

from sklearn.model_selection import train_test_split

# Membagi data menjadi training set dan testing set
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

"""# Langkah 3: Membangun Model Regresi
## Regresi Linier
Kita bisa memulai dengan Regresi Linier untuk memprediksi total penjualan berdasarkan fitur-fitur yang ada.
Berikut adalah beberapa parameter utama yang tersedia untuk LinearRegression

* fit_intercept:
Tipe: Boolean (default: True)
Deskripsi: Menentukan apakah model akan menghitung intercept (konstanta) untuk setiap fitur. Jika diatur ke False, model tidak akan menghitung intercept dan anggap intercept sebagai 0.
* normalize:
Tipe: Boolean (default: False)
Deskripsi: Menentukan apakah fitur harus dinormalisasi sebelum regresi. Jika True, semua fitur akan dinormalisasi sehingga memiliki rata-rata 0 dan varians 1.
* copy_X:
Tipe: Boolean (default: True)
Deskripsi: Jika True, salinan dari X akan dibuat. Jika False, X dapat diubah dalam tempat.
*n_jobs:
Tipe: Integer atau None (default: None)
Deskripsi: Menentukan jumlah pekerjaan yang akan digunakan untuk menghitung regresi. Jika diatur ke -1, semua prosesor akan digunakan.
"""

from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, r2_score

# Membangun model regresi linier
linear_model = LinearRegression()

# Melatih model
linear_model.fit(X_train, y_train)

# Melakukan prediksi pada data uji
y_pred_linear = linear_model.predict(X_test)

# Mengukur kinerja model
mse_linear = mean_squared_error(y_test, y_pred_linear)
r2_linear = r2_score(y_test, y_pred_linear)

print(f'Mean Squared Error (Linear Regression): {mse_linear}')
print(f'R-squared (Linear Regression): {r2_linear}')

"""# Xgboost"""

import xgboost as xgb

# Membangun model XGBoost
xgboost_model = xgb.XGBRegressor(objective ='reg:squarederror', random_state=42)

# Melatih model
xgboost_model.fit(X_train, y_train)

# Melakukan prediksi pada data uji
y_pred_xgb = xgboost_model.predict(X_test)

# Mengukur kinerja model
mse_xgb = mean_squared_error(y_test, y_pred_xgb)
r2_xgb = r2_score(y_test, y_pred_xgb)

print(f'Mean Squared Error (XGBoost): {mse_xgb}')
print(f'R-squared (XGBoost): {r2_xgb}')

"""# Validasi Model:

Cross-Validation: Lakukan k-fold cross-validation untuk memastikan model Anda konsisten pada berbagai subset data.
"""

from sklearn.model_selection import cross_val_score

cv_scores = cross_val_score(xgboost_model, X_train, y_train, cv=5, scoring='r2')
print("Cross-validation R² scores:", cv_scores)
print("Mean R² score:", cv_scores.mean())

"""# Analisis Feature Importance:
*   Identifikasi fitur mana yang paling berpengaruh terhadap prediksi total penjualan.
*   Fitur Unit price, Tax 5%, dan Rating adalah yang paling berpengaruh dalam model, yang menunjukkan bahwa harga dan pajak memainkan peran kunci dalam memprediksi total penjualan.
* Fitur-fitur lain seperti Quantity, tipe pelanggan, dan metode pembayaran memberikan kontribusi yang lebih kecil, namun masih relevan untuk meningkatkan akurasi prediksi.

"""

import matplotlib.pyplot as plt
xgb.plot_importance(xgboost_model, max_num_features=10)
plt.show()

"""# Hyperparameter Tuning:
 meningkatkan performa model melalui hyperparameter tuning menggunakan Grid Search atau Random Search.
"""

from sklearn.model_selection import GridSearchCV

param_grid = {
    'n_estimators': [100, 200, 500],
    'max_depth': [3, 5, 7],
    'learning_rate': [0.01, 0.1, 0.2],
    'subsample': [0.7, 0.8, 1.0],
    'colsample_bytree': [0.7, 0.8, 1.0]
}

grid_search = GridSearchCV(
    estimator=xgboost_model,
    param_grid=param_grid,
    scoring='neg_mean_squared_error',
    cv=5,
    n_jobs=-1,
    verbose=1
)

grid_search.fit(X_train, y_train)
print("Best parameters found: ", grid_search.best_params_)

"""# Melatih dan Mengevaluasi Model XGBoost untuk Prediksi Total Penjualan
Import Library dan Model:

* Kode ini mengimpor library xgboost dan menginisialisasi model XGBoost Regressor dengan parameter terbaik yang telah ditentukan sebelumnya, yaitu colsample_bytree, learning_rate, max_depth, n_estimators, dan subsample.
Melatih Model:

* Model yang telah diinisialisasi (xgb_best) kemudian dilatih (fit) menggunakan data pelatihan (X_train dan y_train). Proses ini mempelajari pola dari data pelatihan untuk digunakan dalam prediksi.
Melakukan Prediksi:

* Setelah model dilatih, kode ini melakukan prediksi pada data uji (X_test) menggunakan metode predict(). Hasil prediksi disimpan dalam variabel y_pred.
Evaluasi Performa Model:

* Kode ini kemudian mengimpor metrik evaluasi dari sklearn.metrics, yaitu mean_squared_error dan r2_score.
mean_squared_error digunakan untuk menghitung kesalahan kuadrat rata-rata (MSE) antara nilai aktual (y_test) dan prediksi (y_pred), yang menunjukkan seberapa besar kesalahan model.
r2_score menghitung koefisien determinasi (R-squared), yang menunjukkan seberapa baik variabel independen dalam model dapat menjelaskan variasi variabel dependen.
Hasil MSE dan R-squared dicetak untuk memberikan gambaran tentang kinerja model yang telah dilatih.
"""

import xgboost as xgb
# Melatih ulang model dengan parameter terbaik
xgb_best = xgb.XGBRegressor(
    colsample_bytree=0.8,
    learning_rate=0.1,
    max_depth=5,
    n_estimators=100,
    subsample=0.7
)

# Fit ulang model dengan data pelatihan
xgb_best.fit(X_train, y_train)

# Melakukan prediksi pada test set
y_pred = xgb_best.predict(X_test)

# Evaluasi performa model
from sklearn.metrics import mean_squared_error, r2_score

mse = mean_squared_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)

print(f"Mean Squared Error (MSE): {mse}")
print(f"R-squared: {r2}")

"""#Evaluasi Model
## Visualisasi Hasil Prediksi
Grafik ini menunjukkan bagaimana hasil prediksi dibandingkan dengan nilai aktual. Idealnya, jika model Anda sempurna, semua titik akan berada pada garis 45 derajat (prediksi = nilai aktual).

* visualisasi tersebut menjawab pertanyaan tentang bagaimana Anda bisa memprediksi total penjualan (Total) dari kombinasi variabel seperti jenis pelanggan, jenis produk, dan lokasi cabang. Berikut adalah beberapa cara visualisasi tersebut mendukung jawaban atas pertanyaan ini:

## Penjelasan
Keterkaitan Variabel:

* Visualisasi menunjukkan bahwa model regresi yang digunakan (XGBoost) berhasil memprediksi total penjualan dengan baik berdasarkan variabel-variabel yang diberikan (jenis pelanggan, jenis produk, dan lokasi cabang). Ini memberikan bukti bahwa model dapat menangkap hubungan antara variabel-variabel tersebut dan total penjualan.
Akurasi Prediksi:

* Dengan nilai prediksi yang hampir identik dengan nilai aktual, visualisasi menunjukkan bahwa model tersebut tidak hanya mampu menghasilkan prediksi, tetapi juga melakukannya dengan tingkat akurasi yang tinggi. Ini mengindikasikan bahwa pendekatan yang digunakan untuk menggabungkan variabel-variabel tersebut efektif.
Metode yang Digunakan:

* Menggunakan model regresi seperti XGBoost menunjukkan bahwa Anda telah menerapkan teknik machine learning yang sesuai untuk memprediksi total penjualan. Hal ini menunjukkan bahwa Anda telah memilih metode yang tepat untuk menangani masalah yang kompleks ini.
* Kesimpulan
Dengan demikian, visualisasi tersebut sangat mendukung pertanyaan awal tentang bagaimana total penjualan dapat diprediksi. Ini menunjukkan bahwa kombinasi variabel yang Anda gunakan memberikan hasil yang kuat dan bahwa model Anda dapat diandalkan untuk memprediksi total penjualan dengan baik.
"""

import matplotlib.pyplot as plt

# Plot Prediksi vs Nilai Aktual
plt.figure(figsize=(8, 6))
plt.scatter(y_test, y_pred, alpha=0.3)
plt.plot([min(y_test), max(y_test)], [min(y_test), max(y_test)], color='red', linestyle='--', lw=2)
plt.xlabel('Nilai Aktual')
plt.ylabel('Nilai Prediksi')
plt.title('Prediksi vs Nilai Aktual')
plt.show()

"""# Residual Plot:
Residual plot dapat membantu mengidentifikasi pola dari error model. Residual adalah selisih antara nilai aktual dan prediksi. Plot residual yang tersebar secara acak di sekitar 0 menunjukkan bahwa model memprediksi dengan baik dan tidak ada pola sistematis dalam error.
"""

# Menghitung residual
residuals = y_test - y_pred

# Plot Residuals
plt.figure(figsize=(8, 6))
plt.scatter(y_pred, residuals, alpha=0.3)
plt.axhline(y=0, color='red', linestyle='--', lw=2)
plt.xlabel('Nilai Prediksi')
plt.ylabel('Residual (Nilai Aktual - Prediksi)')
plt.title('Plot Residual')
plt.show()

"""# Distribusi Error (Histogram dari Residual):
Dengan melihat distribusi residual, Anda bisa mengecek apakah error tersebar dengan normal, yang mengindikasikan model yang baik.

Grafik distribusi residual memberikan pemahaman yang lebih mendalam tentang kinerja model Anda. Dengan mengetahui bahwa model cenderung meremehkan penjualan, Anda dapat mengambil langkah-langkah untuk memperbaikinya.
"""

# Plot distribusi residual (error)
plt.figure(figsize=(8, 6))
plt.hist(residuals, bins=30, color='blue', alpha=0.7)
plt.xlabel('Residual (Nilai Aktual - Prediksi)')
plt.ylabel('Frekuensi')
plt.title('Distribusi Residual')
plt.show()

"""# Mean Absolute Error (MAE) dan Root Mean Squared Error (RMSE) untuk memahami performa model.

Mean Absolute Error (MAE) memberikan rata-rata absolut error yang lebih mudah diinterpretasikan karena tidak memberikan penalti lebih tinggi untuk outlier.
Root Mean Squared Error (RMSE) adalah akar kuadrat dari MSE dan memberikan gambaran yang lebih intuitif terkait dengan skala error.

Berikut adalah penjelasan tentang nilai Mean Absolute Error (MAE) dan Root Mean Squared Error (RMSE) yang Anda berikan:

1. Mean Absolute Error (MAE)
Definisi: MAE adalah rata-rata dari selisih absolut antara nilai yang diprediksi oleh model dan nilai sebenarnya. Ini memberikan gambaran seberapa besar kesalahan prediksi dalam unit yang sama dengan data asli.
Nilai Anda: 1.7389
Interpretasi: Nilai MAE sebesar 1.7389 berarti bahwa, rata-rata, model Anda melakukan kesalahan sebesar 1.7389 unit pada prediksi total penjualan. Semakin kecil nilai MAE, semakin baik kinerja model dalam memprediksi data.
2. Root Mean Squared Error (RMSE)
Definisi: RMSE adalah akar kuadrat dari rata-rata kuadrat kesalahan antara nilai yang diprediksi dan nilai aktual. RMSE memberikan bobot lebih pada kesalahan yang lebih besar karena nilai kesalahan dikuadratkan sebelum dihitung rata-ratanya.
Nilai Anda: 2.6692
Interpretasi: Nilai RMSE sebesar 2.6692 menunjukkan bahwa kesalahan rata-rata prediksi model Anda adalah sekitar 2.6692 unit. RMSE lebih sensitif terhadap outlier dibandingkan MAE, sehingga bisa memberi gambaran yang lebih jelas tentang kinerja model dalam hal prediksi yang jauh dari nilai aktual.
Kesimpulan
MAE dan RMSE keduanya digunakan untuk mengevaluasi kinerja model regresi, dengan RMSE memberikan penekanan lebih pada kesalahan besar. Dalam konteks model Anda, nilai-nilai tersebut menunjukkan bahwa model cukup baik dalam memprediksi total penjualan, meskipun masih ada ruang untuk perbaikan. Sebaiknya, Anda membandingkan nilai ini dengan nilai MAE dan RMSE dari model lain untuk mendapatkan pemahaman yang lebih baik tentang kinerja model Anda.
"""

from sklearn.metrics import mean_absolute_error
import numpy as np

mae = mean_absolute_error(y_test, y_pred)
rmse = np.sqrt(mse)

print(f"Mean Absolute Error (MAE): {mae}")
print(f"Root Mean Squared Error (RMSE): {rmse}")